Tokenization and Padding are used in order to convert sentences to tokens.

- OOV token is 'Out of vocabulary' words.
- Padding is used to make sentences have the same length when converted to a sequence


Stopwords are used to clean text.

Using CSV and JSON datasets along with tfds
Encoding and decoding strings.
