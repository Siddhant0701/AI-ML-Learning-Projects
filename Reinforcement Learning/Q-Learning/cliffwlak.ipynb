{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import random\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CliffWalking-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "\n",
    "q_table = np.zeros((state_size,action_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 10000\n",
    "STEPS = 250 \n",
    "\n",
    "LR = 0.01\n",
    "DISCOUNT = 0.99\n",
    "\n",
    "MIN_EXPLORATION = 0.1\n",
    "MAX_EXPLORATION = 1\n",
    "DECAY = 0.001\n",
    "exploration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rewards = []\n",
    "\n",
    "for episode in range(EPISODES):\n",
    "\n",
    "    state = env.reset()\n",
    "    done= False\n",
    "    rewards = 0\n",
    "\n",
    "    for step in range(STEPS):\n",
    "        rate = random.uniform(0,1)\n",
    "\n",
    "        if(exploration < rate):\n",
    "            action = np.argmax(q_table[state,:])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        q_table[state,action] *= (1-LR)\n",
    "        q_table[state,action] += (LR *(reward + (DISCOUNT* np.max(q_table[new_state, :]))))\n",
    "\n",
    "        state = new_state\n",
    "        rewards += reward\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    exploration = MIN_EXPLORATION + (MAX_EXPLORATION - MIN_EXPLORATION ) * np.exp(-DECAY*episode)\n",
    "    all_rewards.append(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********Average reward per 1000 episodes********\n",
      "\n",
      "1000 :  -1154.797999999998\n",
      "2000 :  -146.33100000000024\n",
      "3000 :  -76.75200000000035\n",
      "4000 :  -54.70500000000006\n",
      "5000 :  -51.987000000000066\n",
      "6000 :  -50.4120000000001\n",
      "7000 :  -52.460000000000065\n",
      "8000 :  -49.31200000000015\n",
      "9000 :  -51.99800000000006\n",
      "10000 :  -52.87799999999996\n",
      "\n",
      "\n",
      "********Q-Table********\n",
      "\n",
      "[[ -10.93666721  -10.93734592  -10.94972192  -10.93940708]\n",
      " [ -10.51288798  -10.51507363  -10.52075897  -10.52439481]\n",
      " [  -9.91770359   -9.91507575   -9.92472504   -9.95329664]\n",
      " [  -9.23867054   -9.23997828   -9.24379202   -9.24624802]\n",
      " [  -8.51543658   -8.51332512   -8.52052492   -8.53061804]\n",
      " [  -7.77841369   -7.76486841   -7.76785394   -7.76512495]\n",
      " [  -7.00102526   -6.98873231   -6.99244472   -7.01150417]\n",
      " [  -6.20615118   -6.20635024   -6.2104534    -6.21336849]\n",
      " [  -5.41591066   -5.4107096    -5.41152545   -5.42540541]\n",
      " [  -4.60981538   -4.59961559   -4.60189602   -4.62521943]\n",
      " [  -3.78315581   -3.77190357   -3.77345781   -3.78667878]\n",
      " [  -2.95749014   -2.96618702   -2.94570022   -3.0038966 ]\n",
      " [ -11.35068159  -11.35294064  -11.35635867  -11.35154873]\n",
      " [ -10.84162436  -10.83954515  -10.84164068  -10.84009388]\n",
      " [ -10.14990842  -10.14993065  -10.15163168  -10.15297774]\n",
      " [  -9.38209171   -9.38189992   -9.38282312   -9.39605566]\n",
      " [  -8.55083339   -8.54543043   -8.5457415    -8.57705945]\n",
      " [  -7.71598552   -7.66828896   -7.66831167   -7.83749449]\n",
      " [  -6.79387257   -6.76263758   -6.76286747   -6.81790538]\n",
      " [  -6.01275763   -5.83581478   -5.83583154   -6.06541093]\n",
      " [  -5.2312819    -4.89362111   -4.8935864    -5.31460756]\n",
      " [  -4.37782399   -3.9374763    -3.93748075   -4.53387206]\n",
      " [  -3.4908682    -2.9693757    -2.96937128   -3.81052844]\n",
      " [  -3.11990128   -2.55871285   -1.98999957   -3.04485553]\n",
      " [ -12.00086224  -11.36151283  -13.0704323   -12.20590849]\n",
      " [ -11.48164463  -10.46617457 -112.02776673  -12.19042886]\n",
      " [ -10.75786039   -9.5617925  -112.01830648  -11.26051696]\n",
      " [ -10.05687717   -8.64827525 -111.94564028  -10.34762995]\n",
      " [  -9.25372858   -7.72553056 -111.92389577   -9.44850999]\n",
      " [  -8.38658288   -6.79346521 -111.8922735    -8.53910296]\n",
      " [  -7.53028717   -5.85198506 -111.88101819   -7.58027187]\n",
      " [  -6.61425182   -4.90099501 -111.73121258   -6.69774279]\n",
      " [  -5.70180929   -3.940399   -111.71596827   -5.74986116]\n",
      " [  -4.78179998   -2.9701     -111.22469385   -4.82221565]\n",
      " [  -3.85541271   -1.99       -111.21580923   -3.89277969]\n",
      " [  -2.94970687   -1.97989382   -1.           -2.94108154]\n",
      " [ -12.2478977  -112.08808598  -13.06889923  -13.0695024 ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]\n",
      " [   0.            0.            0.            0.        ]]\n"
     ]
    }
   ],
   "source": [
    "rewards_per_thousand = np.split(np.array(all_rewards), EPISODES/1000)\n",
    "count = 1000\n",
    "\n",
    "print(\"********Average reward per 1000 episodes********\\n\")\n",
    "for r in rewards_per_thousand:\n",
    "    print(count, \": \", str(sum(r/1000)))\n",
    "    count += 1000\n",
    "\n",
    "print(\"\\n\\n********Q-Table********\\n\")\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  x\n",
      "\n",
      "You reached!\n"
     ]
    }
   ],
   "source": [
    "for episode in range(3):\n",
    "    state=env.reset()\n",
    "    done=False\n",
    "    sleep(1)\n",
    "\n",
    "    for step in range(STEPS):        \n",
    "        clear_output(wait=True)\n",
    "        env.render()\n",
    "        sleep(0.3)\n",
    "        # Choose action with highest Q-value for current state       \n",
    "        # Take new action\n",
    "\n",
    "        action = np.argmax(q_table[state,:])\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            clear_output(wait=True)\n",
    "            env.render()\n",
    "            if reward == -100:\n",
    "               print(f'You fell!')\n",
    "            else:\n",
    "                print(\"You reached!\")           \n",
    "\n",
    "            sleep(3)\n",
    "            clear_output(wait=True)\n",
    "            break\n",
    "        state = new_state"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
